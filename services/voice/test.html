<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Service Test - STT & TTS</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            padding: 40px;
            max-width: 800px;
            width: 100%;
        }

        h1 {
            text-align: center;
            color: #667eea;
            margin-bottom: 10px;
            font-size: 2.5em;
        }

        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 40px;
        }

        .section {
            margin-bottom: 40px;
            padding: 30px;
            background: #f8f9fa;
            border-radius: 15px;
        }

        .section h2 {
            color: #764ba2;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .section h2::before {
            content: '';
            width: 4px;
            height: 24px;
            background: #667eea;
            border-radius: 2px;
        }

        .controls {
            display: flex;
            gap: 15px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }

        button {
            padding: 12px 24px;
            font-size: 16px;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: 600;
            flex: 1;
            min-width: 150px;
        }

        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        }

        button:active {
            transform: translateY(0);
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .btn-primary {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .btn-danger {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
        }

        .btn-success {
            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
            color: white;
        }

        textarea {
            width: 100%;
            padding: 15px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 16px;
            font-family: inherit;
            resize: vertical;
            min-height: 100px;
            transition: border-color 0.3s ease;
        }

        textarea:focus {
            outline: none;
            border-color: #667eea;
        }

        .transcript {
            background: white;
            padding: 20px;
            border-radius: 8px;
            min-height: 150px;
            border: 2px solid #e0e0e0;
            font-size: 16px;
            line-height: 1.6;
            color: #333;
        }

        .transcript.live {
            border-color: #4facfe;
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0%, 100% {
                border-color: #4facfe;
            }
            50% {
                border-color: #00f2fe;
            }
        }

        .status {
            padding: 10px 15px;
            border-radius: 8px;
            margin-top: 15px;
            font-size: 14px;
            display: none;
        }

        .status.show {
            display: block;
        }

        .status.info {
            background: #e3f2fd;
            color: #1976d2;
            border-left: 4px solid #1976d2;
        }

        .status.success {
            background: #e8f5e9;
            color: #388e3c;
            border-left: 4px solid #388e3c;
        }

        .status.error {
            background: #ffebee;
            color: #d32f2f;
            border-left: 4px solid #d32f2f;
        }

        .recording-indicator {
            display: none;
            align-items: center;
            gap: 10px;
            color: #f5576c;
            font-weight: 600;
            margin-top: 15px;
        }

        .recording-indicator.active {
            display: flex;
        }

        .pulse-dot {
            width: 12px;
            height: 12px;
            background: #f5576c;
            border-radius: 50%;
            animation: pulse-dot 1.5s infinite;
        }

        @keyframes pulse-dot {
            0%, 100% {
                opacity: 1;
            }
            50% {
                opacity: 0.3;
            }
        }

        audio {
            width: 100%;
            margin-top: 15px;
            border-radius: 8px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Voice Service Test</h1>
        <p class="subtitle">Speech-to-Text & Text-to-Speech using Azure Cognitive Services</p>

        <!-- Speech to Text Section -->
        <div class="section">
            <h2>üéôÔ∏è Speech to Text (STT)</h2>
            <div class="controls">
                <button id="startRecording" class="btn-primary">Start Recording</button>
                <button id="stopRecording" class="btn-danger" disabled>Stop Recording</button>
            </div>
            <div class="recording-indicator" id="recordingIndicator">
                <div class="pulse-dot"></div>
                <span>Recording...</span>
            </div>
            <div class="transcript" id="transcript">
                <em>Click "Start Recording" to begin transcription...</em>
            </div>
            <div class="status" id="sttStatus"></div>
        </div>

        <!-- Text to Speech Section -->
        <div class="section">
            <h2>üîä Text to Speech (TTS)</h2>
            <textarea id="textInput" placeholder="Enter text to synthesize (e.g., 'Hello, welcome to our banking service!')">Hello, welcome to our banking service! How can I help you today?</textarea>
            <div class="controls">
                <button id="synthesize" class="btn-success">Synthesize Speech</button>
            </div>
            <audio id="audioPlayer" controls style="display: none;"></audio>
            <div class="status" id="ttsStatus"></div>
        </div>
    </div>

    <script>
        const API_URL = 'http://localhost:8001';
        
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;

        const startBtn = document.getElementById('startRecording');
        const stopBtn = document.getElementById('stopRecording');
        const transcriptDiv = document.getElementById('transcript');
        const sttStatus = document.getElementById('sttStatus');
        const recordingIndicator = document.getElementById('recordingIndicator');
        const synthesizeBtn = document.getElementById('synthesize');
        const textInput = document.getElementById('textInput');
        const audioPlayer = document.getElementById('audioPlayer');
        const ttsStatus = document.getElementById('ttsStatus');

        function showStatus(element, message, type) {
            element.textContent = message;
            element.className = `status show ${type}`;
            setTimeout(() => {
                element.className = 'status';
            }, 5000);
        }

        // Speech to Text
        startBtn.addEventListener('click', async () => {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    recordingIndicator.classList.remove('active');
                    transcriptDiv.classList.remove('live');
                    
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    
                    showStatus(sttStatus, 'üîÑ Transcribing...', 'info');
                    
                    try {
                        // Convert blob to base64
                        const reader = new FileReader();
                        reader.readAsDataURL(audioBlob);
                        reader.onloadend = async () => {
                            const base64Audio = reader.result.split(',')[1];
                            
                            const response = await fetch(`${API_URL}/transcribe`, {
                                method: 'POST',
                                headers: {
                                    'Content-Type': 'application/json',
                                },
                                body: JSON.stringify({
                                    audio_bytes: base64Audio,
                                    format: 'wav'
                                })
                            });

                            const data = await response.json();
                            
                            if (response.ok) {
                                transcriptDiv.innerHTML = `<strong>Transcript:</strong><br>${data.transcript}`;
                                showStatus(sttStatus, '‚úÖ Transcription complete!', 'success');
                            } else {
                                throw new Error(data.error || 'Transcription failed');
                            }
                        };
                    } catch (error) {
                        showStatus(sttStatus, `‚ùå Error: ${error.message}`, 'error');
                        transcriptDiv.innerHTML = '<em>Transcription failed. Please try again.</em>';
                    }
                };

                mediaRecorder.start();
                isRecording = true;
                startBtn.disabled = true;
                stopBtn.disabled = false;
                recordingIndicator.classList.add('active');
                transcriptDiv.classList.add('live');
                transcriptDiv.innerHTML = '<em>üé§ Listening... speak now!</em>';
                showStatus(sttStatus, 'üéôÔ∏è Recording started', 'info');

            } catch (error) {
                showStatus(sttStatus, `‚ùå Microphone access denied: ${error.message}`, 'error');
            }
        });

        stopBtn.addEventListener('click', () => {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                isRecording = false;
                startBtn.disabled = false;
                stopBtn.disabled = true;
            }
        });

        // Text to Speech
        synthesizeBtn.addEventListener('click', async () => {
            const text = textInput.value.trim();
            
            if (!text) {
                showStatus(ttsStatus, '‚ö†Ô∏è Please enter some text', 'error');
                return;
            }

            synthesizeBtn.disabled = true;
            showStatus(ttsStatus, 'üîÑ Synthesizing speech...', 'info');
            audioPlayer.style.display = 'none';

            try {
                const response = await fetch(`${API_URL}/synthesize`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ text })
                });

                const data = await response.json();

                if (response.ok) {
                    // Convert base64 to audio
                    const audioData = `data:audio/wav;base64,${data.audio_bytes}`;
                    audioPlayer.src = audioData;
                    audioPlayer.style.display = 'block';
                    audioPlayer.play();
                    showStatus(ttsStatus, '‚úÖ Speech synthesized successfully!', 'success');
                } else {
                    throw new Error(data.error || 'Synthesis failed');
                }
            } catch (error) {
                showStatus(ttsStatus, `‚ùå Error: ${error.message}`, 'error');
            } finally {
                synthesizeBtn.disabled = false;
            }
        });

        // Test connection on load
        window.addEventListener('load', async () => {
            try {
                const response = await fetch(`${API_URL}/health`);
                if (response.ok) {
                    console.log('‚úÖ Voice service is running');
                }
            } catch (error) {
                showStatus(sttStatus, '‚ö†Ô∏è Voice service not reachable. Make sure it\'s running on port 8001', 'error');
            }
        });
    </script>
</body>
</html>
